{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务1：模型训练与预测\n",
    "\n",
    "- 步骤1：导入LightGBM库\n",
    "- 步骤2：使用LGBMClassifier对iris进行训练。\n",
    "- 步骤3：将预测的模型对iris进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,accuracy_score,auc,mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = pd.DataFrame(data = iris.data , columns=iris.feature_names)\n",
    "y = pd.DataFrame(iris.target,columns=['target'])\n",
    "\n",
    "data = pd.concat([X,y],axis=1)\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2022)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测值：[2 2 0 2 0 0 1 1 0 1 1 2 1 2 2 0 1 1 2 1 0 0 2 0 2 2 2 0 1 2]\n",
      "模型f1值：0.9670588235294119\n"
     ]
    }
   ],
   "source": [
    "## sklearn API\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(objective= 'multiclass',\n",
    "                               metric = 'multi_logloss',\n",
    "                               boosting_type= 'gbdt',\n",
    "                               n_estimators= 100,\n",
    "                               learning_rate= 0.2,\n",
    "                               n_jobs= -1,\n",
    "                               random_state= 2022\n",
    "                               )\n",
    "\n",
    "\n",
    "lgb_model.fit(X_train,y_train)\n",
    "y_pre = lgb_model.predict(X_test)\n",
    "print('预测值：{}'.format(y_pre))\n",
    "print('模型f1值：{}'.format(f1_score(y_test,y_pre,average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttraining's multi_logloss: 1.02645\tvalid_1's multi_logloss: 1.04308\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\ttraining's multi_logloss: 0.963391\tvalid_1's multi_logloss: 0.981793\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\ttraining's multi_logloss: 0.906715\tvalid_1's multi_logloss: 0.926843\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\ttraining's multi_logloss: 0.855363\tvalid_1's multi_logloss: 0.877545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\ttraining's multi_logloss: 0.793976\tvalid_1's multi_logloss: 0.818866\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\ttraining's multi_logloss: 0.739769\tvalid_1's multi_logloss: 0.767803\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\ttraining's multi_logloss: 0.69154\tvalid_1's multi_logloss: 0.720422\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\ttraining's multi_logloss: 0.647562\tvalid_1's multi_logloss: 0.6764\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\ttraining's multi_logloss: 0.60761\tvalid_1's multi_logloss: 0.632645\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttraining's multi_logloss: 0.571057\tvalid_1's multi_logloss: 0.592445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\ttraining's multi_logloss: 0.535602\tvalid_1's multi_logloss: 0.559315\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\ttraining's multi_logloss: 0.50324\tvalid_1's multi_logloss: 0.529192\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\ttraining's multi_logloss: 0.473653\tvalid_1's multi_logloss: 0.501768\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\ttraining's multi_logloss: 0.446573\tvalid_1's multi_logloss: 0.477088\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\ttraining's multi_logloss: 0.421748\tvalid_1's multi_logloss: 0.454615\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\ttraining's multi_logloss: 0.397549\tvalid_1's multi_logloss: 0.43156\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\ttraining's multi_logloss: 0.375354\tvalid_1's multi_logloss: 0.410445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\ttraining's multi_logloss: 0.355011\tvalid_1's multi_logloss: 0.391164\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\ttraining's multi_logloss: 0.336354\tvalid_1's multi_logloss: 0.373548\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\ttraining's multi_logloss: 0.319233\tvalid_1's multi_logloss: 0.357446\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\ttraining's multi_logloss: 0.303378\tvalid_1's multi_logloss: 0.338797\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\ttraining's multi_logloss: 0.288728\tvalid_1's multi_logloss: 0.321295\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\ttraining's multi_logloss: 0.275164\tvalid_1's multi_logloss: 0.305098\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\ttraining's multi_logloss: 0.262615\tvalid_1's multi_logloss: 0.289993\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\ttraining's multi_logloss: 0.251003\tvalid_1's multi_logloss: 0.2759\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\ttraining's multi_logloss: 0.239304\tvalid_1's multi_logloss: 0.262521\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\ttraining's multi_logloss: 0.229024\tvalid_1's multi_logloss: 0.252162\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\ttraining's multi_logloss: 0.218819\tvalid_1's multi_logloss: 0.240178\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\ttraining's multi_logloss: 0.209552\tvalid_1's multi_logloss: 0.228269\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\ttraining's multi_logloss: 0.20133\tvalid_1's multi_logloss: 0.219263\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\ttraining's multi_logloss: 0.194281\tvalid_1's multi_logloss: 0.209786\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\ttraining's multi_logloss: 0.187679\tvalid_1's multi_logloss: 0.200866\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\ttraining's multi_logloss: 0.18122\tvalid_1's multi_logloss: 0.191947\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\ttraining's multi_logloss: 0.175428\tvalid_1's multi_logloss: 0.184054\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\ttraining's multi_logloss: 0.170155\tvalid_1's multi_logloss: 0.176662\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\ttraining's multi_logloss: 0.164555\tvalid_1's multi_logloss: 0.169969\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\ttraining's multi_logloss: 0.159327\tvalid_1's multi_logloss: 0.163726\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\ttraining's multi_logloss: 0.154523\tvalid_1's multi_logloss: 0.157865\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\ttraining's multi_logloss: 0.150031\tvalid_1's multi_logloss: 0.152381\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\ttraining's multi_logloss: 0.145825\tvalid_1's multi_logloss: 0.147142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\ttraining's multi_logloss: 0.141347\tvalid_1's multi_logloss: 0.140281\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\ttraining's multi_logloss: 0.137168\tvalid_1's multi_logloss: 0.13387\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\ttraining's multi_logloss: 0.133334\tvalid_1's multi_logloss: 0.129225\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\ttraining's multi_logloss: 0.129743\tvalid_1's multi_logloss: 0.124804\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\ttraining's multi_logloss: 0.12641\tvalid_1's multi_logloss: 0.120682\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\ttraining's multi_logloss: 0.123105\tvalid_1's multi_logloss: 0.115608\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\ttraining's multi_logloss: 0.120076\tvalid_1's multi_logloss: 0.110924\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\ttraining's multi_logloss: 0.117299\tvalid_1's multi_logloss: 0.106448\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\ttraining's multi_logloss: 0.114759\tvalid_1's multi_logloss: 0.102313\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\ttraining's multi_logloss: 0.11237\tvalid_1's multi_logloss: 0.0983425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\ttraining's multi_logloss: 0.109598\tvalid_1's multi_logloss: 0.0961095\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[52]\ttraining's multi_logloss: 0.106669\tvalid_1's multi_logloss: 0.0938578\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[53]\ttraining's multi_logloss: 0.10393\tvalid_1's multi_logloss: 0.0917534\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[54]\ttraining's multi_logloss: 0.10155\tvalid_1's multi_logloss: 0.0901803\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\ttraining's multi_logloss: 0.099394\tvalid_1's multi_logloss: 0.0887408\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[56]\ttraining's multi_logloss: 0.0970302\tvalid_1's multi_logloss: 0.0872328\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[57]\ttraining's multi_logloss: 0.0948084\tvalid_1's multi_logloss: 0.0858697\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[58]\ttraining's multi_logloss: 0.0927178\tvalid_1's multi_logloss: 0.0846403\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[59]\ttraining's multi_logloss: 0.0907396\tvalid_1's multi_logloss: 0.0836651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\ttraining's multi_logloss: 0.0885561\tvalid_1's multi_logloss: 0.0829799\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[61]\ttraining's multi_logloss: 0.0870521\tvalid_1's multi_logloss: 0.0808598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[62]\ttraining's multi_logloss: 0.0857458\tvalid_1's multi_logloss: 0.0794573\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[63]\ttraining's multi_logloss: 0.084728\tvalid_1's multi_logloss: 0.0780778\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[64]\ttraining's multi_logloss: 0.0837802\tvalid_1's multi_logloss: 0.0767726\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[65]\ttraining's multi_logloss: 0.0829712\tvalid_1's multi_logloss: 0.0753167\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[66]\ttraining's multi_logloss: 0.0814196\tvalid_1's multi_logloss: 0.0768186\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[67]\ttraining's multi_logloss: 0.0801549\tvalid_1's multi_logloss: 0.0772317\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[68]\ttraining's multi_logloss: 0.0792031\tvalid_1's multi_logloss: 0.077759\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[69]\ttraining's multi_logloss: 0.0783682\tvalid_1's multi_logloss: 0.0784184\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\ttraining's multi_logloss: 0.0776473\tvalid_1's multi_logloss: 0.0790793\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[71]\ttraining's multi_logloss: 0.0764224\tvalid_1's multi_logloss: 0.0784106\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[72]\ttraining's multi_logloss: 0.0753053\tvalid_1's multi_logloss: 0.0778069\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[73]\ttraining's multi_logloss: 0.074029\tvalid_1's multi_logloss: 0.0775931\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[74]\ttraining's multi_logloss: 0.0721313\tvalid_1's multi_logloss: 0.0795344\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[75]\ttraining's multi_logloss: 0.0711195\tvalid_1's multi_logloss: 0.078508\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[76]\ttraining's multi_logloss: 0.0692613\tvalid_1's multi_logloss: 0.0783387\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[77]\ttraining's multi_logloss: 0.0676299\tvalid_1's multi_logloss: 0.0782138\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[78]\ttraining's multi_logloss: 0.0662295\tvalid_1's multi_logloss: 0.0781248\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[79]\ttraining's multi_logloss: 0.0650381\tvalid_1's multi_logloss: 0.0780646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttraining's multi_logloss: 0.0639819\tvalid_1's multi_logloss: 0.0779193\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[81]\ttraining's multi_logloss: 0.062355\tvalid_1's multi_logloss: 0.0785534\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[82]\ttraining's multi_logloss: 0.0607118\tvalid_1's multi_logloss: 0.0793156\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[83]\ttraining's multi_logloss: 0.0592303\tvalid_1's multi_logloss: 0.0800313\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[84]\ttraining's multi_logloss: 0.0578022\tvalid_1's multi_logloss: 0.080491\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[85]\ttraining's multi_logloss: 0.0566217\tvalid_1's multi_logloss: 0.0795679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[86]\ttraining's multi_logloss: 0.0554581\tvalid_1's multi_logloss: 0.078331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[87]\ttraining's multi_logloss: 0.0543481\tvalid_1's multi_logloss: 0.0770778\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[88]\ttraining's multi_logloss: 0.0533378\tvalid_1's multi_logloss: 0.075957\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[89]\ttraining's multi_logloss: 0.0525371\tvalid_1's multi_logloss: 0.0759818\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\ttraining's multi_logloss: 0.0515701\tvalid_1's multi_logloss: 0.0754123\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[91]\ttraining's multi_logloss: 0.0506388\tvalid_1's multi_logloss: 0.0714213\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[92]\ttraining's multi_logloss: 0.0498988\tvalid_1's multi_logloss: 0.0676832\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[93]\ttraining's multi_logloss: 0.0493336\tvalid_1's multi_logloss: 0.064189\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[94]\ttraining's multi_logloss: 0.0489286\tvalid_1's multi_logloss: 0.0609295\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[95]\ttraining's multi_logloss: 0.0486704\tvalid_1's multi_logloss: 0.0578955\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[96]\ttraining's multi_logloss: 0.0472775\tvalid_1's multi_logloss: 0.0590937\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[97]\ttraining's multi_logloss: 0.0460502\tvalid_1's multi_logloss: 0.0601983\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[98]\ttraining's multi_logloss: 0.0449641\tvalid_1's multi_logloss: 0.0612161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[99]\ttraining's multi_logloss: 0.0439879\tvalid_1's multi_logloss: 0.0628553\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\ttraining's multi_logloss: 0.0431119\tvalid_1's multi_logloss: 0.064516\n",
      "[[1.14754244e-03 1.22398722e-02 9.86612585e-01]\n",
      " [1.32339645e-03 1.51471614e-02 9.83529442e-01]\n",
      " [9.97349389e-01 2.19910780e-03 4.51502801e-04]\n",
      " [1.32504703e-03 1.10559728e-02 9.87618980e-01]\n",
      " [9.97306572e-01 2.29969346e-03 3.93734050e-04]\n",
      " [9.95881753e-01 3.43436758e-03 6.83879404e-04]\n",
      " [2.34068250e-03 9.91638244e-01 6.02107377e-03]\n",
      " [2.23739943e-03 9.85549208e-01 1.22133921e-02]\n",
      " [9.97303987e-01 2.29968749e-03 3.96325398e-04]\n",
      " [2.01879484e-03 9.92838711e-01 5.14249387e-03]\n",
      " [3.89912924e-03 9.78665833e-01 1.74350379e-02]\n",
      " [1.32339645e-03 1.51471614e-02 9.83529442e-01]\n",
      " [1.75932080e-03 9.91484338e-01 6.75634123e-03]\n",
      " [1.07772499e-03 5.87232967e-03 9.93049945e-01]\n",
      " [1.38157794e-03 2.06331097e-02 9.77985312e-01]\n",
      " [9.96708885e-01 2.91767525e-03 3.73439644e-04]\n",
      " [2.29680837e-03 9.95638696e-01 2.06449575e-03]\n",
      " [7.31310920e-03 3.82216096e-01 6.10470795e-01]\n",
      " [1.33343151e-03 9.03292098e-03 9.89633648e-01]\n",
      " [1.18018921e-03 9.95813504e-01 3.00630636e-03]\n",
      " [9.95118529e-01 4.49203693e-03 3.89433631e-04]\n",
      " [9.96902786e-01 2.71860396e-03 3.78610253e-04]\n",
      " [1.12552018e-03 1.22401421e-02 9.86634338e-01]\n",
      " [9.97303987e-01 2.29968749e-03 3.96325398e-04]\n",
      " [1.07480185e-03 8.96518835e-03 9.89960010e-01]\n",
      " [1.86928014e-02 6.02993965e-01 3.78313233e-01]\n",
      " [3.18289457e-03 1.32834277e-01 8.63982828e-01]\n",
      " [9.96685940e-01 2.91760808e-03 3.96452055e-04]\n",
      " [3.52339669e-03 9.36173670e-01 6.03029335e-02]\n",
      " [2.02508196e-03 3.43949492e-02 9.63579969e-01]]\n",
      "预测值：[2, 2, 0, 2, 0, 0, 1, 1, 0, 1, 1, 2, 1, 2, 2, 0, 1, 2, 2, 1, 0, 0, 2, 0, 2, 1, 2, 0, 1, 2]\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "## 原生API\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class':3, # 多分类，需指定类别数\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train,y_train)\n",
    "lgb_val = lgb.Dataset(X_test,y_test,reference=lgb_train)\n",
    "\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "          lgb_train,\n",
    "          num_boost_round=100,\n",
    "          valid_sets=[lgb_train, lgb_val]\n",
    "          )\n",
    "\n",
    "# predict ,输出的是每个类别的概率\n",
    "y_pre = gbm.predict(X_test)\n",
    "print(y_pre) \n",
    "\n",
    "# 输出类别 (这里是输出最大值的index)\n",
    "y_pre = [list(x).index(max(x)) for x in y_pre]\n",
    "print('预测值：{}'.format(y_pre))\n",
    "print(accuracy_score(y_test,y_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务2：模型保存与加载\n",
    "\n",
    "https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/advanced_example.py\n",
    "- 步骤1：将任务1训练得到的模型，使用pickle进行保存。\n",
    "- 步骤2：将任务1训练得到的模型，使用json进行保存。\n",
    "- 步骤3：加载步骤1和步骤2的模型，并进行预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 2, 0, 0, 1, 1, 0, 1, 1, 2, 1, 2, 2, 0, 1, 1, 2, 1, 0, 0,\n",
       "       2, 0, 2, 2, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pickle 保存模型\n",
    "\n",
    "import pickle\n",
    "def pkl_save(filename,file):\n",
    "    output = open(filename, 'wb')\n",
    "    pickle.dump(file, output)\n",
    "    output.close()\n",
    "\n",
    "def pkl_load(filename):\n",
    "    pkl_file = open(filename, 'rb')\n",
    "    file = pickle.load(pkl_file) \n",
    "    pkl_file.close()\n",
    "    return file\n",
    "\n",
    "## 模型保存\n",
    "pkl_save('./lgb_model.pkl',lgb_model)\n",
    "\n",
    "## 加载模型\n",
    "lgb_pkl_load = pkl_load('./lgb_model.pkl')\n",
    "\n",
    "## 预测\n",
    "lgb_pkl_load.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 2, 0, 0, 1, 1, 0, 1, 1, 2, 1, 2, 2, 0, 1, 1, 2, 1, 0, 0,\n",
       "       2, 0, 2, 2, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# sklearn.externals.joblib被弃用了\n",
    "\n",
    "## 模型保存\n",
    "joblib.dump(lgb_model,'lgb_model.pkl')\n",
    "\n",
    "## 加载模型\n",
    "lgb_joblib_load = joblib.load('./lgb_model.pkl')\n",
    "\n",
    "## 预测\n",
    "lgb_joblib_load.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json\n",
    "\n",
    "Pickle 和 Joblib 库简单快捷，易于使用，但是在不同的 Python 版本之间存在兼容性问题，且不同模型也有所不同。json的兼容性较好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 保存模型\n",
    "model_json = gbm.dump_model()\n",
    "with open('model.json', 'w+') as f:\n",
    "    json.dump(model_json, f, indent=4)\n",
    "\n",
    "# 加载模型\n",
    "with open('model.json', 'r', encoding=\"UTF-8\") as f:\n",
    "\t\tgbm = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务3：分类、回归和排序任务\n",
    "\n",
    "https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/sklearn_example.py\n",
    "https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/simple_example.py\n",
    "\n",
    "- 步骤1：学习LightGBM中sklearn接口的使用，导入分类、回归和排序模型。\n",
    "- 步骤2：学习LightGBM中原生train接口的使用。\n",
    "- 步骤3：二分类任务\n",
    "    - 使用make_classification，创建一个二分类数据集。\n",
    "    - 使用sklearn接口完成训练和预测。\n",
    "    - 使用原生train接口完成训练和预测。\n",
    "- 步骤4：多分类任务\n",
    "    - 使用make_classification，创建一个多分类数据集。\n",
    "    - 使用sklearn接口完成训练和预测。\n",
    "    - 使用原生train接口完成训练和预测。\n",
    "- 步骤5：回归任务\n",
    "    - 使用make_regression，创建一个回归数据集。\n",
    "    - 使用sklearn接口完成训练和预测。\n",
    "    - 使用原生train接口完成训练和预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier,LGBMRegressor,LGBMRanker\n",
    "\n",
    "gbm = LGBMClassifier(num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        objective= 'multiclass',\n",
    "                        metric = 'multi_logloss',\n",
    "                        n_estimators=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.0261\n",
      "[2]\tvalid_0's multi_logloss: 0.950545\n",
      "[3]\tvalid_0's multi_logloss: 0.883557\n",
      "[4]\tvalid_0's multi_logloss: 0.823806\n",
      "[5]\tvalid_0's multi_logloss: 0.770362\n",
      "[6]\tvalid_0's multi_logloss: 0.722259\n",
      "[7]\tvalid_0's multi_logloss: 0.6787\n",
      "[8]\tvalid_0's multi_logloss: 0.639354\n",
      "[9]\tvalid_0's multi_logloss: 0.59707\n",
      "[10]\tvalid_0's multi_logloss: 0.562639\n",
      "[11]\tvalid_0's multi_logloss: 0.53251\n",
      "[12]\tvalid_0's multi_logloss: 0.499115\n",
      "[13]\tvalid_0's multi_logloss: 0.46795\n",
      "[14]\tvalid_0's multi_logloss: 0.442578\n",
      "[15]\tvalid_0's multi_logloss: 0.415798\n",
      "[16]\tvalid_0's multi_logloss: 0.39598\n",
      "[17]\tvalid_0's multi_logloss: 0.373211\n",
      "[18]\tvalid_0's multi_logloss: 0.351421\n",
      "[19]\tvalid_0's multi_logloss: 0.336921\n",
      "[20]\tvalid_0's multi_logloss: 0.318347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.fit(X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric='multi_logloss')\n",
    "\n",
    "y_pre = gbm.predict(X_test,num_iteration=gbm.best_iteration_)\n",
    "\n",
    "accuracy_score(y_test,y_pre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原生接口使用\n",
    "\n",
    "1. lightgbm.train 训练参数\n",
    "- params ：传入参数\n",
    "- train_set：传递数据和标签 ，通过train_data = lgb.Dataset(train_x, train_y)生成\n",
    "- num_boost_round:最大迭代次数\n",
    "- valid_sets：指定训练过程中用于评估的数据及数据的名称，例如：[train_data, valid_data]\n",
    "  ```python\n",
    "  train_data = lgb.Dataset(train_x, train_y)\n",
    "  valid_data = lgb.Dataset(valid_x, valid_y, reference=train)\n",
    "  ```\n",
    "- fobj：指定二阶可导的自定义目标函数\n",
    "- feval：自定义评估函数\n",
    "- categorical_feature：指定类别特征\n",
    "- early_stopping_rounds：迭代多少次没有得到优化则停止训练（valid_sets 必须非空才能生效）\n",
    "- verbose_eval：每间隔verbose_eval次迭代就输出一次信息\n",
    "- init_model：加载之前训练好的 lgb 模型，用于增量训练\n",
    "\n",
    "2. 预测\n",
    "   \n",
    "   predict(data, num_iteration=None)\n",
    "   \n",
    "   num_iteration：选择第几次迭代用于预测，如果使用了 early_stopping_rounds，那么最佳的一次迭代将被使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification,make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier,LGBMRegressor\n",
    "from lightgbm import plot_importance\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.989884\n",
      "[2]\tvalid_0's auc: 0.990477\n",
      "[3]\tvalid_0's auc: 0.990572\n",
      "[4]\tvalid_0's auc: 0.99082\n",
      "[5]\tvalid_0's auc: 0.990802\n",
      "[6]\tvalid_0's auc: 0.991\n",
      "[7]\tvalid_0's auc: 0.991089\n",
      "[8]\tvalid_0's auc: 0.989823\n",
      "[9]\tvalid_0's auc: 0.990392\n",
      "[10]\tvalid_0's auc: 0.990382\n",
      "[11]\tvalid_0's auc: 0.990481\n",
      "[12]\tvalid_0's auc: 0.990486\n",
      "[13]\tvalid_0's auc: 0.990539\n",
      "[14]\tvalid_0's auc: 0.990532\n",
      "[15]\tvalid_0's auc: 0.990523\n",
      "[16]\tvalid_0's auc: 0.990416\n",
      "[17]\tvalid_0's auc: 0.99044\n",
      "[18]\tvalid_0's auc: 0.991358\n",
      "[19]\tvalid_0's auc: 0.991745\n",
      "[20]\tvalid_0's auc: 0.991767\n",
      "[21]\tvalid_0's auc: 0.991617\n",
      "[22]\tvalid_0's auc: 0.991527\n",
      "[23]\tvalid_0's auc: 0.991269\n",
      "[24]\tvalid_0's auc: 0.99124\n",
      "[25]\tvalid_0's auc: 0.991032\n",
      "[26]\tvalid_0's auc: 0.990972\n",
      "[27]\tvalid_0's auc: 0.99074\n",
      "[28]\tvalid_0's auc: 0.990755\n",
      "[29]\tvalid_0's auc: 0.990702\n",
      "[30]\tvalid_0's auc: 0.990664\n",
      "[31]\tvalid_0's auc: 0.990502\n",
      "[32]\tvalid_0's auc: 0.990419\n",
      "[33]\tvalid_0's auc: 0.990436\n",
      "[34]\tvalid_0's auc: 0.990477\n",
      "[35]\tvalid_0's auc: 0.99083\n",
      "[36]\tvalid_0's auc: 0.990886\n",
      "[37]\tvalid_0's auc: 0.991007\n",
      "[38]\tvalid_0's auc: 0.990966\n",
      "[39]\tvalid_0's auc: 0.99094\n",
      "[40]\tvalid_0's auc: 0.990927\n",
      "[41]\tvalid_0's auc: 0.990971\n",
      "[42]\tvalid_0's auc: 0.991053\n",
      "[43]\tvalid_0's auc: 0.991181\n",
      "[44]\tvalid_0's auc: 0.99138\n",
      "[45]\tvalid_0's auc: 0.991546\n",
      "[46]\tvalid_0's auc: 0.991473\n",
      "[47]\tvalid_0's auc: 0.991436\n",
      "[48]\tvalid_0's auc: 0.991615\n",
      "[49]\tvalid_0's auc: 0.991731\n",
      "[50]\tvalid_0's auc: 0.991698\n",
      "[51]\tvalid_0's auc: 0.991786\n",
      "[52]\tvalid_0's auc: 0.991883\n",
      "[53]\tvalid_0's auc: 0.992077\n",
      "[54]\tvalid_0's auc: 0.992005\n",
      "[55]\tvalid_0's auc: 0.992137\n",
      "[56]\tvalid_0's auc: 0.992212\n",
      "[57]\tvalid_0's auc: 0.992242\n",
      "[58]\tvalid_0's auc: 0.992257\n",
      "[59]\tvalid_0's auc: 0.992182\n",
      "[60]\tvalid_0's auc: 0.992233\n",
      "[61]\tvalid_0's auc: 0.992276\n",
      "[62]\tvalid_0's auc: 0.992268\n",
      "[63]\tvalid_0's auc: 0.992261\n",
      "[64]\tvalid_0's auc: 0.992242\n",
      "[65]\tvalid_0's auc: 0.992187\n",
      "[66]\tvalid_0's auc: 0.992278\n",
      "[67]\tvalid_0's auc: 0.992295\n",
      "[68]\tvalid_0's auc: 0.992262\n",
      "[69]\tvalid_0's auc: 0.99222\n",
      "[70]\tvalid_0's auc: 0.992135\n",
      "[71]\tvalid_0's auc: 0.99217\n",
      "[72]\tvalid_0's auc: 0.992174\n",
      "[73]\tvalid_0's auc: 0.992163\n",
      "[74]\tvalid_0's auc: 0.992184\n",
      "[75]\tvalid_0's auc: 0.992186\n",
      "[76]\tvalid_0's auc: 0.992188\n",
      "[77]\tvalid_0's auc: 0.99218\n",
      "[78]\tvalid_0's auc: 0.992164\n",
      "[79]\tvalid_0's auc: 0.99216\n",
      "[80]\tvalid_0's auc: 0.992219\n",
      "[81]\tvalid_0's auc: 0.992161\n",
      "[82]\tvalid_0's auc: 0.992132\n",
      "[83]\tvalid_0's auc: 0.99213\n",
      "[84]\tvalid_0's auc: 0.99203\n",
      "[85]\tvalid_0's auc: 0.992007\n",
      "[86]\tvalid_0's auc: 0.991994\n",
      "[87]\tvalid_0's auc: 0.991944\n",
      "[88]\tvalid_0's auc: 0.991931\n",
      "[89]\tvalid_0's auc: 0.991888\n",
      "[90]\tvalid_0's auc: 0.991891\n",
      "[91]\tvalid_0's auc: 0.991878\n",
      "[92]\tvalid_0's auc: 0.991907\n",
      "[93]\tvalid_0's auc: 0.991886\n",
      "[94]\tvalid_0's auc: 0.991889\n",
      "[95]\tvalid_0's auc: 0.991881\n",
      "[96]\tvalid_0's auc: 0.991905\n",
      "[97]\tvalid_0's auc: 0.991906\n",
      "[98]\tvalid_0's auc: 0.991908\n",
      "[99]\tvalid_0's auc: 0.991934\n",
      "[100]\tvalid_0's auc: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1147, 1126, 484, 561, 996, 1142]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## sklearn接口\n",
    "\n",
    "X,y = make_classification(n_samples=10000,n_features=6,n_classes=2,random_state=2022)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=2022)\n",
    "\n",
    "lgb_model = LGBMClassifier(num_leaves=100,\n",
    "                           max_depth=10,\n",
    "                           boosting_type='gbdt',\n",
    "                           learning_rate=0.1,\n",
    "                           n_estimators=100,\n",
    "                           objective='binary',\n",
    "                           subsample=0.8,  # 子采样，选择小于1的比例可以减少方差，即防止过拟合，但会增加样本拟合的偏差\n",
    "                           colsample_bytree=1,  # 特征随机采样的比例\n",
    "                           reg_alpha=0.1,\n",
    "                           reg_lambda=0.1,\n",
    "                           metrics='auc',\n",
    "                           random_state=2022\n",
    "                           )\n",
    "\n",
    "# 训练\n",
    "lgb_model.fit(X_train,\n",
    "              y_train,\n",
    "              eval_set=[(X_test,y_test)],\n",
    "              eval_metric='auc'\n",
    "              )\n",
    "# 预测\n",
    "y_pre = lgb_model.predict(X_test)\n",
    "accuracy_score(y_test,y_pre)\n",
    "\n",
    "# 特征重要性\n",
    "list(lgb_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: booster\n",
      "[LightGBM] [Warning] Unknown parameter: 0.01\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8\n",
      "[LightGBM] [Warning] Unknown parameter: slient\n",
      "[LightGBM] [Warning] Unknown parameter: booster\n",
      "[LightGBM] [Warning] Unknown parameter: 0.01\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8\n",
      "[LightGBM] [Warning] Unknown parameter: slient\n",
      "[LightGBM] [Info] Number of positive: 3532, number of negative: 3468\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 7000, number of used features: 6\n",
      "[LightGBM] [Warning] Unknown parameter: booster\n",
      "[LightGBM] [Warning] Unknown parameter: 0.01\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8\n",
      "[LightGBM] [Warning] Unknown parameter: slient\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504571 -> initscore=0.018286\n",
      "[LightGBM] [Info] Start training from score 0.018286\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0279068\tvalid_1's binary_logloss: 0.110315\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's binary_logloss: 0.0558673\tvalid_1's binary_logloss: 0.102256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9603333333333334"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 原生train接口\n",
    "\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary',\n",
    "    'num_leaves': 31,\n",
    "    'subsample': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction ': 0.8,\n",
    "    'slient': 1,\n",
    "    'learning_rate ': 0.01,\n",
    "    'seed': 2022\n",
    "}\n",
    "\n",
    "\n",
    "dtrain = lgb.Dataset(X_train,y_train)\n",
    "dtest = lgb.Dataset(X_test,y_test,reference=dtrain)\n",
    "\n",
    "# 训练\n",
    "model = lgb.train(params=params,\n",
    "          train_set=dtrain,\n",
    "          num_boost_round=500,\n",
    "          valid_sets=[dtrain,dtest],\n",
    "          verbose_eval=100,\n",
    "          early_stopping_rounds=100)\n",
    "\n",
    "# 预测\n",
    "y_pre = model.predict(X_test) # 输出的是每个类别的概率\n",
    "y_pre = np.where(y_pre>0.5,1,0)\n",
    "accuracy_score(y_test,y_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tvalid_0's multi_logloss: 0.32074\n",
      "[40]\tvalid_0's multi_logloss: 0.2485\n",
      "[60]\tvalid_0's multi_logloss: 0.236102\n",
      "[80]\tvalid_0's multi_logloss: 0.234227\n",
      "[100]\tvalid_0's multi_logloss: 0.237341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9136666666666666"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## sklearn接口\n",
    "\n",
    "X,y = make_classification(n_samples=10000,n_features=12,n_classes=3,n_informative=6 ,random_state=2022)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=2022)\n",
    "\n",
    "lgb_model = LGBMClassifier(num_leaves=100,\n",
    "                           max_depth=10,\n",
    "                           boosting_type='gbdt',\n",
    "                           learning_rate=0.1,\n",
    "                           n_estimators=100,\n",
    "                           objective='muticlass', # 改成多类别目标\n",
    "                           num_class = 3, # 指定类别数\n",
    "                           subsample=0.8,  # 子采样，选择小于1的比例可以减少方差，即防止过拟合，但会增加样本拟合的偏差\n",
    "                           colsample_bytree=1,  # 特征随机采样的比例\n",
    "                           reg_alpha=0.1,\n",
    "                           reg_lambda=0.1,\n",
    "                           metrics='multi_logloss',\n",
    "                           random_state=2022\n",
    "                           )\n",
    "\n",
    "# 训练\n",
    "lgb_model.fit(X_train,\n",
    "              y_train,\n",
    "              eval_set=[(X_test,y_test)],\n",
    "              eval_metric='multi_logloss',\n",
    "              verbose=20\n",
    "              )\n",
    "# 预测\n",
    "y_pre = lgb_model.predict(X_test)\n",
    "accuracy_score(y_test,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: booster\n",
      "[LightGBM] [Warning] Unknown parameter: 0.01\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8\n",
      "[LightGBM] [Warning] Unknown parameter: slient\n",
      "[LightGBM] [Warning] Unknown parameter: booster\n",
      "[LightGBM] [Warning] Unknown parameter: 0.01\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8\n",
      "[LightGBM] [Warning] Unknown parameter: slient\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 7000, number of used features: 12\n",
      "[LightGBM] [Warning] Unknown parameter: booster\n",
      "[LightGBM] [Warning] Unknown parameter: 0.01\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8\n",
      "[LightGBM] [Warning] Unknown parameter: slient\n",
      "[LightGBM] [Info] Start training from score -1.103912\n",
      "[LightGBM] [Info] Start training from score -1.094478\n",
      "[LightGBM] [Info] Start training from score -1.097470\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.0674972\tvalid_1's multi_logloss: 0.23427\n",
      "[200]\ttraining's multi_logloss: 0.0153117\tvalid_1's multi_logloss: 0.24024\n",
      "Early stopping, best iteration is:\n",
      "[126]\ttraining's multi_logloss: 0.0452042\tvalid_1's multi_logloss: 0.231654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9113333333333333"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 原生train接口\n",
    "\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'num_leaves': 31,\n",
    "    'subsample': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction ': 0.8,\n",
    "    'slient': 1,\n",
    "    'learning_rate ': 0.01,\n",
    "    'seed': 2022\n",
    "}\n",
    "\n",
    "\n",
    "dtrain = lgb.Dataset(X_train,y_train)\n",
    "dtest = lgb.Dataset(X_test,y_test,reference=dtrain)\n",
    "\n",
    "\n",
    "# 训练\n",
    "model = lgb.train(params=params,\n",
    "                  train_set=dtrain,\n",
    "                  num_boost_round=500,\n",
    "                  valid_sets=[dtrain, dtest],\n",
    "                  verbose_eval=100,\n",
    "                  early_stopping_rounds=100)\n",
    "\n",
    "# 预测\n",
    "y_pre = model.predict(X_test) # 输出的是每个类别的概率\n",
    "y_pre = np.argmax(y_pre,axis=1) # 返回概率最大的index，也就是类别\n",
    "\n",
    "accuracy_score(y_test,y_pre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's l2: 110.266\tvalid_1's l2: 287.75\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's l2: 110.266\tvalid_1's l2: 287.75\n",
      "mse 287.7500552404751\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEWCAYAAADVW8iBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwU9Z3/8dcbwROEKIoImgmKgoAzCsGYZc24Bi8wxiNBo6x4JLqbxBOPn27UTUwkiNdGs67X6qJBNIhBYhQUxtsoE0E8QtCIATWoxAMQlOPz+6NqhmaYo2Gmp6fa9/Px6AfV1VVdn8+g86Wqq79vRQRmZmZZ0K7YBZiZmeXLg5aZmWWGBy0zM8sMD1pmZpYZHrTMzCwzPGiZmVlmeNAyKwGSLpZ0a7HrMCs0+Xta9kUnaQHQDViTs3qPiHinme95WkQ82rzqskfS5cDuEXFisWux0uMzLbPEERHRMeexyQNWS5DUvpjH31RZrduyw4OWWQMkdZZ0m6R3Jb0t6QpJm6Wv7SZphqQlkj6QdLekLulr44FdgQclLZN0gaRKSYvqvP8CSd9Mly+X9FtJd0n6BBjV2PHrqfVySXely2WSQtLJkhZK+lDSGZK+KuklSR9JuiFn31GSnpb0K0kfS/qzpINyXt9Z0hRJ/5D0uqTv1zlubt1nABcDI9Le56TbnSzpNUlLJf1V0uk571EpaZGk8yS9l/Z7cs7rW0m6WtJbaX1PSdoqfe1rkp5Je5ojqXKT/rItMzxomTXsTmA1sDuwD3AwcFr6moArgZ2BvsAuwOUAETES+Bvrzt7G5nm8I4HfAl2Au5s4fj72A3oDI4DrgEuAbwL9gO9K+kadbf8KdAUuA+6XtF362gRgUdrrscAvcge1OnXfBvwCmJj2Xp5u8x4wHNgWOBm4VtK+Oe+xE9AZ6AGcCtwo6Uvpa+OAgcDXge2AC4C1knoAvweuSNePBiZJ2mEjfkaWMR60zBIPpP9a/0jSA5K6AYcBZ0fE8oh4D7gWOA4gIl6PiOkR8VlEvA9cA3yj4bfPy7MR8UBErCX55d7g8fP0s4hYGRHTgOXAhIh4LyLeBp4kGQhrvAdcFxGrImIiMA8YJmkXYAhwYfpes4FbgZH11R0RK+orJCJ+HxFvROJxYBrwzzmbrAJ+mh7/IWAZsKekdsApwFkR8XZErImIZyLiM+BE4KGIeCg99nRgFnD4RvyMLGN8/dks8e3cmyYkDQY6AO9KqlndDliYvr4j8F8kv3g7pa992MwaFuYsf7mx4+dpcc7yinqed8x5/nasf1fWWyRnVjsD/4iIpXVeG9RA3fWSdBjJGdweJH1sDczN2WRJRKzOef5pWl9XYEvgjXre9svAdyQdkbOuAzCzqXosuzxomdVvIfAZ0LXOL9MaVwIB7B0RSyR9G7gh5/W6t+UuJ/lFDUD62VTdy1i5+zR1/JbWQ5JyBq5dgSnAO8B2kjrlDFy7Am/n7Fu31/WeS9oCmAT8K/C7iFgl6QGSS6xN+QBYCewGzKnz2kJgfER8f4O9rGT58qBZPSLiXZJLWFdL2lZSu/Tmi5pLgJ1ILmF9lH62cn6dt1gM9Mp5/hdgS0nDJHUA/gPYohnHb2k7AmdK6iDpOySf0z0UEQuBZ4ArJW0paW+Sz5zubuS9FgNl6aU9gM1Jen0fWJ2edR2cT1HppdLbgWvSG0I2k7R/OhDeBRwh6ZB0/ZbpTR09N759ywoPWmYN+1eSX7ivklz6+y3QPX3tP4F9gY9Jbga4v86+VwL/kX5GNjoiPgb+neTzoLdJzrwW0bjGjt/S/khy08YHwM+BYyNiSfra8UAZyVnXZOCy9POjhtyX/rlE0p/SM7QzgXtJ+vgeyVlcvkaTXEp8AfgH8EugXTqgHklyt+L7JGde5+PfayXNXy42+4KTNIrki9BDil2LWVP8LxIzM8sMD1pmZpYZvjxoZmaZ4TMtMzPLDH9Pq4V16dIldt9992KXURDLly9nm222KXYZBVGqvZVqX+Desqqh3qqrqz+IiCan4PKg1cK6devGrFmzil1GQVRVVVFZWVnsMgqiVHsr1b7AvWVVQ71Jeiuf/X150MzMMsODlpmZZYYHLTMzywwPWmZmlhketMzMLDM8aJmZWWZ40DIzs8zwoGVmZpnhQcvMzDLDg5aZmWWGBy0zM8sMD1pmZraBsrIyBgwYQEVFBYMGDQLg8ssvp0ePHlRUVFBRUcFDDz1Uu/1LL73E/vvvT79+/RgwYAArV64sSF2eMNfMzOo1c+ZMunbtut66c845h9GjR6+3bvXq1Zx44omMHz+e8vJylixZQocOHQpSU1EGLUk7AdcBXwU+AxYAZ0fEX+rZtgyYGhH9W7HEmmMPBO4AtgIeAs6KJlIzV6xaQ9lFv2+F6lrfeQNWM8q9ZUqp9gXurRAWjBm2SftNmzaNvffem/LycgC23377lixrPa1+eVCSgMlAVUTsFhF7ARcD3Vq7ljz8N/ADoHf6OLS45ZiZtQ5JHHzwwQwcOJCbb765dv0NN9zA3nvvzSmnnMKHH34IwF/+8hckccghh7DvvvsyduzYwtXVxIlDyx9Q+hfg8og4oM56AWOBw4AAroiIiblnWpJGAYMi4kfpPlOBcRFRJWkZcCPwTeBDkoFwLLAryVnclHT/bwFbA7sBkyPiggbq7A7MjIg+6fPjgcqIOL2ebX9AMrjRtesOAy+97pZN/fG0ad22gsUril1FYZRqb6XaF7i3QhjQo3Pt8gcffEDXrl358MMPGT16NGeeeSa77LILnTt3RhK33347S5Ys4cILL2TixIk88MAD3HTTTWyxxRacd955nHLKKQwcOHCDYyxbtoyOHTtusP7AAw+sjohBTdVYjMuD/YHqetYfDVQA5UBX4AVJT2zE+25DcvZ2oaTJwBXAUGAv4E5gSrpdBbAPyWXJeZJ+FREL63m/HsCinOeL0nUbiIibgZsBdu21e1w9tzQ/KjxvwGrcW7aUal/g3gphwQmV9a6fM2cOq1at4uijj65d16tXL4YPH05lZSV///vfWbFiBUceeSQAL7zwAmvXrq037LG5AZdt6W98CDAhItYAiyU9TvKZ10t57v858HC6PBf4LCJWSZoLlOVs91hEfAwg6VXgy0B9g5bqWdfkaelWHTZj3iZeF27rqqqqGvyPOutKtbdS7QvcWyEtX76ctWvX0qlTJ5YvX860adO49NJLeffdd+nevTsAkydPpn//5FaDQw45hLFjx/Lpp5+y+eab8/jjj3POOecUpLZiDFqvAMfWs76+QaKu1az/OdyWOcurcm6SWEtyJkVErJWU2+dnOctraPhnsAjomfO8J/BOHjWamWXa4sWLOeqoo4DkzsDvfe97HHrooYwcOZLZs2cjibKyMv7nf/4HgC996Uuce+65fPWrX0UShx9+OMOGFeYf78UYtGYAv5D0/Yi4BUDSV0k+hxoh6U5gO+AA4HzWH5gWAP8uqR3JpbrBhSoyIt6VtFTS14A/Av8K/KpQxzMzayt69erFnDlzNlg/fvz4Bvc58cQTOfHEEwtZFlCEQSsiQtJRwHWSLgJWkt7yDnQE5pBchrsgIv6e3ohR42ngTZLLfy8Dfypwuf/Gulve/5A+zMysSIrymVZEvAN8t56Xzk8fudsuILl5g/Ty3wkNvGfHnOXL63stIu4gGYRq1g9vos5ZNcc2M7Pi8zROZmaWGW3p7sGikfRHYIs6q0dGxNxi1GNmZvXzoAVExH7FrsHMzJrmy4NmZpYZHrTMzCwzPGiZmVlmeNAyM7NaGxP++Pzzz9euKy8vZ/LkyQWvzzdimJnZevINf+zfvz+zZs2iffv2vPvuu5SXl3PEEUfQvn3hhhaHQDZA0tbAfSQRJmuAByPioqb2cwhkNpVqb6XaF7i3lrYpAZBbb7117fLKlStJEqYKyyGQjRuX5mntA/yTpMOKXZCZWSFtTPgjwB//+Ef69evHgAEDuOmmmwp6lgUOgWwwBLKeuq8HXq6Z5LfOaw6BzLhS7a1U+wL31tJqAiA3Jvwx11tvvcWYMWO4/vrr2XzzzRs8TnNDIImIVn0AZwLX1rP+GGA6sBnJWdffgO4kWVgvp9uMAm7I2WcqSZowJAPdYenyZGAa0IEkVHJ2zv5/BTqTzB7/FrBLHjV3Sffr1dS2e+yxR5SqmTNnFruEginV3kq1rwj31houu+yyuOqqq9Zb9+abb0a/fv3q3b6ysjJeeOGFRt+zod6AWZHHGNKW7h6sDYGMiMVATQhkvuqGQD4eEavS5bKc7R6LiI8jYiVQEwLZoDSLawLwXxHx142ox8wsU5YvX87SpUtrl6dNm0b//v159913a7fJDX988803Wb16NZCcac2bN4+ysrKC1ugQyKZ/BjcD8yPiujzqMzPLrI0Nf3zqqacYM2YMHTp0oF27dvz617/e4K7DluYQyEZIuoLkUuJphTyOmVlbsLHhjyNHjmTkyJGFLms9DoFsgKSewCXAn4E/pbdy3hARtxbqmGZm1jiHQDZc4yLyu2RpZmatpC3diGFmZtYoT+OEQyDNzLLCgxYOgTQzywpfHjQzs8zwoGVmZpnhQcvMrI1Zs2YN++yzD8OHJzc4z5kzh/33358BAwZwxBFH8MknnwCwYMECttpqq9pMqzPOOKOYZbcKD1pmZm3MpEmT6Nu3b+3z0047jTFjxjB37lyOOuoorrrqqtrXdtttN2bPns3s2bO56aabilFuqyrKoCVpJ0n3SHpD0quSHpK0RwPblkl6ubVrTI+9uaSbJf1F0p8lHVOMOszsi2PRokU899xznHbauol45s2bxwEHJMEYQ4cOZdKkScUqr+ha/e7BnDytOyPiuHRdBcnM7huEQBbZJcB7EbFHOnXUdk3t4BDIbCrV3kq1Lyi93mpCGM8++2xOP/102rVbd07Rv39/pkyZwpFHHsl9993HwoULa19788032Weffdh222254oor+Od//udWr701FeNM60CSyW1rz2MjYjbwlKSrJL0saa6kEXV3lDRK0g05z6dKqkyXl0n6paRqSY9KGiypStJfJX0rZ//7JT0sab6ksU3UegpwZVrj2oj4oNndm5k1YOrUqey4447sueee662//fbbufHGGxk4cCBLly6tzavq3r07f/vb33jxxRe55ppr+N73vlf7eVepKsb3tPoD1fWsPxqoIMm/6gq8IOmJjXjfbUjSkC+UNBm4AhgK7AXcCUxJt6sgSSL+DJgn6VcRsbDum0nqki7+LB0Y3wB+lMam1N02NwSSSwes3oiys6PbVsm/bktRqfZWqn1B6fVWVVXFhAkTmDZtGpMmTWLVqlV8+umnDB06lEsuuYSLL74YgIULF7LjjjtSVVW1wXtsv/32TJgwYYNBry1ZtmxZvbXnLZ/QrZZ80HAI5LXAKTnPx5OkDJeRXwjkZ6xLYv4pcEm63A74KGf/W3L2/wMwpIE6u5JM3HtM+vxcYHxT/TkEMptKtbdS7Sui9HubOXNmDBs2LCIiFi9eHBERa9asiZEjR8Ztt90WERHvvfderF69OiIi3njjjdh5551jyZIlxSk6T1kMgXwFGFjP+oLlabH+GWW+eVpLgE9JPn8DuA/YN48azcxa1IQJE9hjjz3o06cPO++8MyeffDIATzzxBHvvvTfl5eUce+yx3HTTTWy3XZMfvWea87QaEBEh6UGgMq35IJKkYzOzgqusrKSyshKAs846i7POOmuDbY455hiOOeaLdVOz87QadyEwXtJ1wPvAyQU+npmZNcJ5Wo3X+RbJGZ+ZmbUBnhHDzMwyw9EkOE/LzCwrPGjhPC0zs6zw5UEzM8sMD1pmZpYZHrTMzCwzPGiZmRVY3VDHESNG1AY3lpWVUVFRAcDzzz9PRUUFp512GuXl5UyePLmxt/1C8o0YZmYFdv3119O3b9/aGdgnTpxY+9p5551H586dgSSCZNasWTz11FPsueeelJeXc8QRR9C+vX9V1yjomVaGwh5/LmmhpGV11h8g6U+SVks6thi1mVm2LVq0iN///vfrhTrWiAjuvfdejj/+eAC23nrr2gFq5cqVJPGDlqtgw3fGwh4fBG4A5tdZ/zeSmeFH5/tGDoHMplLtrVT7grbfW26o49ixY1m6dOkG2zz55JN069aN3r1716774x//yKhRo/jggw8YP368z7LqKORPo96wRyWuAg4jmWPwioiYmLujpFHAoIj4Ufp8KjAuIqrSs6EbgW+STLJ7MTAW2BU4OyKmpPt/C9ga2A2YHBEXNFRoRDyXHqfu+gXp+rWNNeo8rewr1d5KtS9o+71VVVXx7LPPsmrVKpYuXcrs2bNZsmTJellS1157LYMHD94gX+qGG25gyZIlXHzxxWyzzTa1oY+loLl5WoUctDIR9tgSIuJm4GaAXXvtHlfPLc1/GZ03YDXuLVtKtS9o+70tOKGSRx55hOrqakaNGsXKlSv55JNPuPXWW7nrrrtYvXo1I0aMoLq6mp49e663b1VVFcOHD+eOO+5gu+22Y9CgQUXqouVVVVXVzl6/KYrxNz4EmBARa4DFkh4Hvgq8lOf+nwMPp8tzgc8iYpWkuSSBkTUei4iPASS9CnwZKMiglWurDpsxL70sUGqqqqpYcEJlscsoiFLtrVT7gmz0duWVV3LllVcCSb3jxo3jrrvuAuDRRx+lT58+6w1Yb775JrvssgsAb731FvPmzaOsrKzV627LCjlovQLUd/NCwcIeJW1K2KOZWau75557am/AqPHUU08xZswYPvvsM7bddlt+/etf07Vr1yJV2DYV8hd5JsIezcxaQ26oI8Add9yxwTYjR45k5MiRzb6EVsoKdst7ejZ0FDA0veX9FeBy4DcklwLnkAxsF0TE3+vsnhv2OI4Chz1KGitpEbC1pEWSLk/XfzVd/x3gf9IezMysSAp6ySxDYY8XABvcXRgRLwA9N9zDzMyKwdM4mZlZZnyhbk5w2KOZWbZ9oQYthz2amWWbLw+amVlmeNAyM7PM8KBlZmaZ4UHLzKwedYMbf/KTn7D33ntTUVHBwQcfzDvvvAPA559/zsknn8yAAQMoLy9v1mSw1jQPWmZm9agJbqxx/vnn89JLLzF79myGDx/OT3/6UwBuueUWAObOncv06dM577zzWLu20WAIa4ai3D0oaSfgOpKJcj8jmbbp7IjYIGdLUhkwNSL6t2KJNceuAroDK9JVB0fEe43t4zytbCrV3kq1LyhMbzUZWDXBjZdccgnXXHMNANtuu23tdsuXL6+NMnr11Vc56KCDANhxxx3p0qULs2bNYvBgzz5XCK1+ppUTDlkVEbtFxF4kmVjdWruWPJ0QERXpo9EBy8xKQ01wY7t26/+KvOSSS9hll124++67a8+0ysvL+d3vfsfq1at58803qa6uZuHCggdKfGEV40wrM+GQ+XIIZPaVam+l2hcUpremghuHDh3K0KFDufvuuxk9ejQnn3wyu+22G9OnT6dPnz5069aNPn368NprrzXrs63mBiW2ZW05BLIhWQuH/F9Ja4BJJANp1N3AIZDZV6q9lWpfUJjemgpurPGVr3yFYcOGceeddwLUXh4E+PrXv87RRx/NXnvttcl1lPIs71kMgWxIWwyHPCEi3pbUiWTQGgn8X2NFOAQym0q1t1LtCwrXW0PBjfPnz6d3794ATJkyhT59+gDw6aefEhFss802TJ8+nfbt2zdrwLLGFWPQykw4ZES8nf65VNJvSHK9Gh20zKw0XXTRRcybN4927drx5S9/mZtuSj7heO+99zjkkENo164dPXr0YPz48UWutLQVY9DKRDhkOtB1iYgPJHUAhgOPFup4Ztb25AY3Tpo0qd5tysrKmDdvXitW9cXW6oNWRISko4DrJF0ErCS95R3oSBIOGaThkOkt7zVywyFfprDhkFsAj6QD1mYkA9YtBTyemZk1Ia9BS9JuwKKI+ExSJbA38H8R8dGmHDQL4ZARsRwY2EgbZmbWyvL9ntYkYI2k3YHbgK8AvylYVWZmZvXI9/Lg2ohYXXNZLyJ+JenFQhbWmhwOaWaWDfkOWqskHQ+cBByRrutQmJJan8MhzcyyId/LgycD+wM/j4g3JX0FuKuJfczMzFpUXmdaEfGqpAtJpkQiIt4ExhSyMDMzs7ryOtOSdAQwm3TGCUkVkqY0vpeZmVnLyvfy4OUkX+T9CJIJbknuIDSzBixcuJADDzyQvn370q9fP66//nqg4TDBu+++m4qKitpHu3btmD17djFbMGtz8h20VtfM15djg4lj8yVpJ0n3SHpD0quSHpK0RwPblkl6eVOP1RySjpc0V9JLkh6W1LUYdVg2tW/fnquvvprXXnuN5557jhtvvJFXX321wTDBE044gdmzZzN79mzGjx9PWVkZFRUVRe7CrG3J9+7BlyV9D9hMUm/gTOCZTTlgTp7WnRFxXLqugiRPa4MQyGJJp3G6HtgrncppLPAjkrPOBjkEMptaurcFY4bRvXt3unfvDkCnTp3o27cvb7/99nqTqeaGCeaaMGECxx9/fIvVY1Yq8j3T+jHQj2Sy2d8AH5NMu7Qp6s3TAp6SdJWkl9OzmxF1d5Q0StINOc+npjN0IGmZpF9Kqpb0qKTBkqok/VXSt3L2vz89a5qfDkQNUfrYJh1otwXe2cSe7QtuwYIFvPjii+y3X/LtivrCBHNNnDjRg5ZZPVRPPNT6G0ibAY9ExDdb5IDSmcBXIuKcOuuPAc4ADiXN0wL2I/nS79SI6N9ECGQAh0fEH9I8rW2AYaR5WhFRke5/KTl5WsCQhvK0JB0L3A4sB+YDB6bRKXW3yw2BHHjpdaU5RWG3rWDximJXURgt3duAHp1rl1esWMFZZ53FiSeeyAEHHLDednfffTeff/45J598cu26V199lXHjxnH77bc3u45ly5bRsWPHpjfMIPeWTQ31duCBB1ZHxKAm3yAimnyQBCh2zmfbPN7rTODaetZfC5yS83w8ScpwGfByum4UcEPONlOBynT5M9YNwj8FLkmX2wEf5ex/S87+fyAZtOqrswPwGEnCsYAbgP9oqr899tgjStXMmTOLXULBFKq3zz//PA4++OC4+uqr6319wYIF0a9fv/XWnX322fHzn/+8RY7vv7Ns+iL2BsyKPMaQfD/TWgnMlTSd5KyjZsA7M8/9c2UlT6si3f8NAEn3AhflUaMZkPyD8NRTT6Vv376ce+65tesbChMEWLt2Lffddx9PPLExod1mXxz5Dlq/Tx8tIRN5WsDbwF6SdoiI94GhwGsFPJ6VmKeffprx48czYMCA2rsAf/GLX3DbbbfVGyYI8MQTT9CzZ0969epVrLLN2rR8Z8S4s6UOGJGNPK2IeEfSfwJPSFoFvEVyedEsL0OGDGHdyf86hx9+eIP7VFZW8txzzxWyLLNMyzdP603q+V5WRGzSPwcjA3la6es3ATc1to2ZmbWefC8P5t7RsSXwHZJLeGZmZq0m38uDS+qsuk7SUyS3j2ee87TMzLIh38uD++Y8bUdy5tWpIBUVQThPy8wsE/K9PHh1zvJqkpsh6vtMyszMrGDyHbROjYi/5q5IgyDNzMxaTb5zD/42z3VmZmYF0+igJalPOidgZ0lH5zxGsf6Xfq3IysrKar/EOmhQcrPnfffdR79+/WjXrh2zZs0qcoVmZs3X1OXBPYHhQBfgiJz1S4HvF6oo2zQzZ86ka9d1kV/9+/fn/vvv5/TTTy9iVWZmLafRQSsifgf8TtL+EfHsxr65pJ2A64Cvksz5twA4OyI2yM1KZ76YGhH9N/Y4zSXp58C/Al/K/ZKypC2A/wMGAkuAEemXnTOhb9++xS7BzKxF5XsjxouSfkiSqVV7WTAiTmloh6yEPaYeJJnFfX6d9acCH0bE7pKOA34JbJDzlau1QyAXjBkGgCQOPvhgJHH66afzgx/8oNVqMDNrLfkOWuOBPwOHkMR+nEDTk8fWG/aoxFXAYSRTQ10RERNzd2wiN2sZcCPwTZJJdi8GxgK7kpzFTUn3/xawNUm0yOSIuKChQiPiufQ4dV86knVJxb8FbpCknNnka+rNzdPi0gGrm/jRtJyqqioArrrqKrp27cqHH37I6NGjWbFiBeXl5QB89NFHVFdXs2zZsmYda9myZbXHKzWl2lup9gXuLaua21u+g9buEfEdSUdGxJ2SfgM80sQ+/YHqetYfTRL7UU4a9ihpY3IYtgGqIuLCNOzxCpIZ2PcC7iTJ/iI9Rm3Yo6RfRQNhj43oASwEiIjVkj4Gtgc+yN0oIm4GbgbYtdfucfXcfH+szbfghMoN1s2ZM4dVq1ZRWZm81qVLFwYOHFh7g8amqqqqqn3PUlOqvZVqX+Desqq5veX723VV+udHkvoDfycJZ9wUQ4AJkSQAL5b0OMlnXi/luf/nwMPp8lzgs4hYJWlunZoei4iPASS9CnyZdADaCPVlfDUa9bxVh82Yl16yay3Lly9n7dq1dOrUieXLlzNt2jQuvbQkZtgyM1tPvt/TulnSl4CfkJzJvEpySa4xr5DcwFBXwcIeWX8QzjfssTGLgF0A0iDJzsA/NuF9Cmrx4sUMGTKE8vJyBg8ezLBhwzj00EOZPHkyPXv25Nlnn2XYsGEccsghxS7VzKxZ8p0w99Z08XEg3ziSrIQ9NmYKcBLwLEna8oy6n2e1Bb169WLOnDkbrD/qqKM46qijilCRmVlh5HWmJambpNsk/SF9vpekUxvbJ/3lfhQwVNIbkl4huanhNySXAueQDGwXRMTf6+yeG/Y4jgKGPQJIGitpEbC1pEWSLk9fug3YXtLrwLnARYWsw8zMGpfvJbM7gP8FLkmf/wWYSPJLvUEZCnu8ANjg7sKIWEmSHWZmZm1Avp9pdY2Ie0k+QyIiVpN8TmRmZtZq8j3TWi5pe9I75yR9Dfi4YFUViMMezcyyLd9B61ySmxJ2k/Q0sAPJjQmZ4rBHM7Nsa3TQkrRrRPwtIv4k6RskE+gKmBcRqxrb18zMrKU19ZnWAznLEyPilYh42QOWmZkVQ1ODVu4XgfP9fpaZmVlBNPWZVjSwbG3ImjVrGDRoED169GDq1KmMGDGCefPmAclkuV26dGH27NlFrtLMrPmaGrTKJX1Ccsa1VbpM+p0f80UAABOYSURBVDwiYtuCVmd5uf766+nbty+ffJL89UycuG7S/PPOO4/OnTsXqzQzsxbVVAjkZoU4aBbCISV1Ap7MWdUTuCsizm5sv9bK06rJ0Vq0aBG///3vueSSS7jmmmvW2yYiuPfee5kxY0bB6zEzaw2tl6GRyko4ZEQsJYk3AUBSNXB/8Sqq39lnn83YsWNZunTpBq89+eSTdOvWjd69exehMjOzltfqgxYZCofMOW5vYEfWP/PKfb3VQyCrqqp49tlnWbVqFUuXLmX27NksWbJkvXC1a6+9lsGDB7dYmJyD6bKnVPsC95ZVrRUC2ZKyGA55PMkt//XejFKMEMgFJ1TyyCOPUF1dzahRo1i5ciWffPIJt956K3fddRerV69mxIgRVFdX07NnzxY5poPpsqdU+wL3llWtFQLZGtpyOORxwMh8imjNEMgrr7ySK6+8Ekj+Qxg3bhx33XUXAI8++ih9+vRpsQHLzKwtyHfC3JaUqXBISeVA+4io7+ywzbrnnns4/vjji12GmVmLKsagNQPYQtL3a1bUCYfcTNIOJOGQz9fZdwFQIamdpF1onXDI44EJrXCcZqmsrGTq1Km1z++44w7OOOOMIlZkZtbyWv3yYESEpKOA6yRdBKwkveUd6EgSDhmk4ZDpLe81csMhX6bA4ZCp7wKHt8JxzMysCUX5TCsr4ZDpNp6+ysysjSjG5UEzM7NN0pbuHiwah0OamWWDBy0cDmlmlhW+PGhmZpnhQcvMzDLDg5aZmWWGB60MW7NmDfvssw/Dh69/5/64ceOQxAcffFCkyszMCsODVobVhD/mWrhwIdOnT2fXXXctUlVmZoVTlLsHsxACmR77YaA7yc/pSeCH6YS+DSp0CGRT4Y/nnHMOY8eO5cgjjyxYDWZmxdLqZ1o5IZBVEbFbROxFkn3VrbVrycN3I6KcZEaOHYDvFLmeWjXhj+3arfsrnDJlCj169KC8vLyIlZmZFY5DIBsJgYyIT9LF9sDmaV0baM0QyIbCHx9++GEuvPBCrrrqKqqqqli5ciVPP/00nTt3brFjO5gue0q1L3BvWeUQyHUKEgIp6RGS2eT/APy2vm1aMwSyofDHW265hSVLlvCjH/0IgA8++IAf//jHPP/88+y0004tcmwH02VPqfYF7i2rHAK5TkFCICPiEElbAncD/wJMb6yI1giBrC/8cdKkSettU1ZWxqxZs+jatWtBazEza00Ogcxj4I6IlSRnar67wcysiBwC2QBJHSV1T5fbk2Rq/blQx9tUdcMfayxYsMBnWWZWchwC2bBtgCmStgA2Ixlsb2p8FzMzKySHQDZc42KSz9TMzKyN8IwYZmaWGW3p7sGicQikmVk2eNDCIZBmZlnhy4NmZpYZHrTMzCwzPGhlUN0crX/84x8MHTqU3r17M3ToUD788MMiV2hmVhgetDKobo7WmDFjOOigg5g/fz4HHXQQY8aMKWJ1ZmaFU5RBS9JOku6R9IakVyU9JGmPBrYtk/Rya9eYHnuEpJckvSJpbDFqqKsmR+u0006rXfe73/2Ok046CYCTTjqJBx54oFjlmZkVVKvfPZiTp3VnRByXrqsgydPaIASyWCRtD1wFDIyI9yXdKemgiHissf0KFQJZE/5Yk6O1dOnS2tcWL15M9+7dAejevTvvvfdeix/fzKwtKMaZVr15WsBTkq6S9LKkuZJG1N1R0ihJN+Q8nyqpMl1eJumXkqolPSppsKQqSX+V9K2c/e+X9LCk+U2cPfUC/hIR76fPHwWOaXb3zTB16lR23HFHBg6sb75hM7PS5zythvO0Xgf6pHMfLgK+TRIEuYHWCIGsqqpiwoQJTJs2jfvvv5/PP/+cTz/9lKFDh7LtttsyadIktt9+e5YsWUKnTp0KEiDnYLrsKdW+wL1lVRZDIBvSpvK0IuJDSf8GTCSJOnmG5OxrA7khkHvuuWf8+ITCJJjkBqfV5GhNnTqV888/n/nz53PMMccwZswYjjvuuIIEyDmYLntKtS9wb1nV3N6cp9XIwB0RD0bEfhGxPzAPmJ9Hja3uoosuYvr06fTu3Zvp06dz0UUXFbskM7OCcJ5WIyTtmP75JeDfgVsLebyNkZujtf322/PYY48xf/58HnvsMbbbbrsiV2dmVhjO02rc9ZLK0+WfRkSbubvRzOyLyHlajdd5fGOvm5lZ6/KMGGZmlhlt6e7BonGelplZNnjQwnlaZmZZ4cuDZmaWGR60zMwsMzxomZlZZnjQyoiVK1cyePBgysvL6devH5dddhkAs2fP5mtf+xoVFRUMGjSI55+v+31sM7PS4RsxMmKLLbZgxowZdOzYkVWrVjFkyBAOO+wwLr30Ui677DIOO+wwHnroIS644IKSnWjTzMwhkI2Q9HNJCyUtK8bx69RCx47J96dXrVrFqlWrkIQkPvnkEwA+/vhjdt5552KWaWZWUA6BbNyDwA1sxES5hQiBrAmAXLNmDQMHDuT111/nhz/8Ifvttx/XXXcdhxxyCKNHj2bt2rU888wzLXpsM7O2ROsmRm+lA0r/AlweEQfUWS9gLHAYydyDV0TExHTuwakR0V/SKGBQRPwo3WcqMC4iqtKzoRuBb5JMvntx+n67AmdHxJR0/28BWwO7AZMj4oI8al6WO01UPa/n5mkNvPS6W/L9ceRlQI/O6z1ftmwZP/nJTzjzzDN58MEHKS8v5xvf+AYzZ85k6tSpXH311S16/Nzj1pztlZpS7a1U+wL3llUN9XbggQdWR8SgpvZ3CGTDIZB5y83T2rXX7nH13Jb9sS44oXKDddXV1SxZsoTHHnuMSZMmIYlvfOMbXHvttQXL4XHGT/aUal/g3rKqub21pRsx2lQI5KbaqsNmzEsv57Wk999/nw4dOtClSxdWrFjBo48+yoUXXsjOO+/M448/TmVlJTNmzKB3794tfmwzs7aiGIPWK8Cx9awvWAikpE0KgWxL3n33XU466STWrFnD2rVr+e53v8vw4cPp0qULZ511FqtXr2bLLbfk5ptvLnapZmYFU4xf2DOAX0j6fkTcAhuEQN4JbEcSAnk+6w9MC4B/l9QO6EGBQyDbkr333psXX3xxg/VDhgyhurq+q61mZqWn1W95T8+GjgKGpre8vwJcDvyG5FLgHJKB7YKI+Hud3XNDIMdR4BBISWMlLQK2lrRI0uWFPJ6ZmTXOIZCN13kB0OTdhWZm1jo8jZOZmWVGJm5CKDSHQJqZZYMHLRwCaWaWFb48aGZmmeFBy8zMMsODlpmZZYYHrTZm4cKFHHjggfTt25d+/fpx/fXXAzBixAgqKiqoqKigrKyMioqKIldqZtb6fCNGG9O+fXuuvvpq9t13X5YuXcrAgQMZOnQoEydOrN3mvPPOo3Pnzo28i5lZaSrKoCVpJ+A6kglxPyOZnunsiNggTys3mqQVS6xbwxSgVz41NCdPa8GYYXTv3p3u3bsD0KlTJ/r27cvbb7/NXnvtBUBEcO+99zJjxoxNOoaZWZa1+uXBnBDIqojYLSL2Ism+6tbateRD0tFAUZKLFyxYwIsvvsh++627I//JJ5+kW7duns3dzL6QHALZSAikpI4kcSc/AO5t6EyrpUIgc8MeV6xYwVlnncWJJ57IAQes+1Fde+219OjRg+9+t75ZsArrixhMl3Wl2he4t6xyCOQ6hQiB/BlwNfBpYwduqRDImrDHVatWMXz4cM444wzOPffc2tdXr17NiBEjqK6upmfPnpt0jOZwMF32lGpf4N6yyiGQ67RoCKSkCmD3iDgnPdvLS3NDICOCU089lb59+643YAE8+uij9OnTpygDlplZW1CMW95fAQbWs75gIZCsPzjnGwK5PzBQ0gLgKWAPSVV51NgsTz/9NOPHj2fGjBm1t7g/9NBDANxzzz0cf/zxhS7BzKzNcghkAyLiv4H/TusrI/lcrbJQx6sxZMgQGvqc8Y477ij04c3M2rRWH7QiIiQdBVwn6SJgJekt70BHkhDIIA2BrHNpLjcE8mUKHAJpZmZti0Mg86u3tgYzMyseT+NkZmaZ0ZbuHiwah0CamWWDBy0cAmlmlhW+PGhmZpnhQcvMzDLDg5aZmWWGBy0zM8sMD1pmZpYZHrTMzCwzPGiZmVlmtHoIZKmTtBSYV+w6CqQr8EGxiyiQUu2tVPsC95ZVDfX25YjYoamd/eXiljcvn/TNLJI0y71lS6n2Be4tq5rbmy8PmplZZnjQMjOzzPCg1fJuLnYBBeTesqdU+wL3llXN6s03YpiZWWb4TMvMzDLDg5aZmWWGB60WJOlQSfMkvS7pomLXszEk3S7pPUkv56zbTtJ0SfPTP7+U89r/S/ucJ+mQ4lSdH0m7SJop6TVJr0g6K12f6f4kbSnpeUlz0r7+M12f6b5ySdpM0ouSpqbPS6I3SQskzZU0W9KsdF2p9NZF0m8l/Tn9f27/Fu0tIvxogQewGfAG0AvYHJgD7FXsujai/gOAfYGXc9aNBS5Kly8Cfpku75X2twXwlbTvzYrdQyO9dQf2TZc7AX9Je8h0f4CAjulyB+CPwNey3ledHs8FfgNMLbH/JhcAXeusK5Xe7gROS5c3B7q0ZG8+02o5g4HXI+KvEfE5cA9wZJFryltEPAH8o87qI0n+AyT989s56++JiM8i4k3gdZL+26SIeDci/pQuLwVeA3qQ8f4isSx92iF9BBnvq4aknsAw4Nac1SXRWwMy35ukbUn+AXwbQER8HhEf0YK9edBqOT2AhTnPF6XrsqxbRLwLyS9+YMd0fWZ7lVQG7ENyVpL5/tLLZ7OB94DpEVESfaWuAy4A1uasK5XeApgmqVrSD9J1pdBbL+B94H/Ty7q3StqGFuzNg1bLUT3rSvX7BJnsVVJHYBJwdkR80tim9axrk/1FxJqIqAB6AoMl9W9k88z0JWk48F5EVOe7Sz3r2mRvqX+KiH2Bw4AfSjqgkW2z1Ft7ko8Z/jsi9gGWk1wObMhG9+ZBq+UsAnbJed4TeKdItbSUxZK6A6R/vpeuz1yvkjqQDFh3R8T96eqS6S+9BFMFHEpp9PVPwLckLSC51P4vku6iNHojIt5J/3wPmExySawUelsELErP+AF+SzKItVhvHrRazgtAb0lfkbQ5cBwwpcg1NdcU4KR0+STgdznrj5O0haSvAL2B54tQX14kieQa+2sRcU3OS5nuT9IOkrqky1sB3wT+TMb7AoiI/xcRPSOijOT/pRkRcSIl0JukbSR1qlkGDgZepgR6i4i/Awsl7ZmuOgh4lZbsrdh3mpTSAzic5M60N4BLil3PRtY+AXgXWEXyr59Tge2Bx4D56Z/b5Wx/SdrnPOCwYtffRG9DSC45vATMTh+HZ70/YG/gxbSvl4FL0/WZ7quePitZd/dg5nsj+dxnTvp4peZ3RSn0ltZaAcxK/7t8APhSS/bmaZzMzCwzfHnQzMwyw4OWmZllhgctMzPLDA9aZmaWGR60zMwsMzxomW0ESWvSmblrHmWb8B7flrRXy1cHknaW9NtCvHcjx6yQdHhrHtO+uNoXuwCzjFkRybRJzfFtYCrJly7zIql9RKxuartIZlo4thm1bRRJ7Um+lzMIeKi1jmtfXD7TMmsmSQMlPZ5OfvpIznQ135f0Qpp3NUnS1pK+DnwLuCo9U9tNUpWkQek+XdOpi5A0StJ9kh4kmVx1GyW5Zy+kk5FukCIgqUxpJlq6/wOSHpT0pqQfSTo33fc5Sdul21VJuk7SM5JeljQ4Xb9duv9L6fZ7p+svl3SzpGnA/wE/BUak/YyQNDh9rxfTP/fMqed+SQ8ryVUam1P3oZL+lP6sHkvXNdmvfQEV+9vTfviRpQewhnWzakwmiQN5BtghfX0EcHu6vH3OflcAP06X7wCOzXmtChiULncFFqTLo0hmJ9kuff4L4MR0uQvJ7Cvb1KmvjDQTLd3/dZIMsR2Aj4Ez0teuJZk4uOb4t6TLB+Ts/yvgsnT5X4DZ6fLlQDWwVc5xbsipYVugfbr8TWBSznZ/BToDWwJvkcw7twPJTN9fSbfLu18/vngPXx402zjrXR5MZ1XvD0xPpjhkM5LpsAD6S7qC5BduR+CRTTje9IioyTk7mGQS2dHp8y2BXUnywRoyM5IMsaWSPgYeTNfPJZkGqsYESHLVJG2bzmk4BDgmXT9D0vaSOqfbT4mIFQ0cszNwp6TeJNNndch57bGI+BhA0qvAl0mm+XkikjwlmtmvlTgPWmbNI+CViNi/ntfuAL4dEXMkjSKZQ68+q1l3qX7LOq8tr3OsYyJi3kbU91nO8tqc52tZ////uvO5BY3HRiyv57UaPyMZLI9Kb1SpaqCeNWkNquf4sGn9WonzZ1pmzTMP2EHS/pBEoEjql77WCXhXSSzKCTn7LE1fq7EAGJguN3YTxSPAj9NZ65G0T/PLrzUifc8hwMfp2dATpHVLqgQ+iPpzyOr20xl4O10elcexnwW+kc7yTc1nbRS2X8soD1pmzRARn5MMNL+UNIfks66vpy//hCQheTpJZEiNe4Dz05sLdgPGAf8m6RmSz7Qa8jOSS20vpTdb/KwFW/kwPf5NJDP8Q/LZ1SBJLwFjWBctUddMYK+aGzGAscCVkp4muVzaqIh4H/gBcH/6M5yYvlTIfi2jPMu72RecpCpgdETMKnYtZk3xmZaZmWWGz7TMzCwzfKZlZmaZ4UHLzMwyw4OWmZllhgctMzPLDA9aZmaWGf8fhI0MNMtIXjcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## sklearn接口\n",
    "\n",
    "X,y = make_regression(n_samples=10000,n_features=12,n_informative=6 ,random_state=2022)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=2022)\n",
    "\n",
    "lgb_model = LGBMRegressor(\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=31,\n",
    "    max_depth=-1,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    objective='regression', # 默认是二分类\n",
    "    min_split_gain=0.0,\n",
    "    min_child_samples=20,\n",
    "    subsample=1.0,\n",
    "    subsample_freq=0,\n",
    "    colsample_bytree=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    random_state=2022,\n",
    "    silent=True\n",
    ")\n",
    "\n",
    "\n",
    "lgb_model.fit(X_train,y_train, eval_set=[(X_train, y_train), (X_test, y_test)], \n",
    "          verbose=100, early_stopping_rounds=50)\n",
    "\n",
    "# 对测试集进行预测\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "print('mse', mse)\n",
    "\n",
    "# 显示重要特征\n",
    "plot_importance(lgb_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: booster\n",
      "[LightGBM] [Warning] Unknown parameter: 0.01\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8\n",
      "[LightGBM] [Warning] Unknown parameter: slient\n",
      "[LightGBM] [Warning] Unknown parameter: booster\n",
      "[LightGBM] [Warning] Unknown parameter: 0.01\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8\n",
      "[LightGBM] [Warning] Unknown parameter: slient\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 7000, number of used features: 12\n",
      "[LightGBM] [Warning] Unknown parameter: booster\n",
      "[LightGBM] [Warning] Unknown parameter: 0.01\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8\n",
      "[LightGBM] [Warning] Unknown parameter: slient\n",
      "[LightGBM] [Info] Start training from score 2.522089\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 109.09\tvalid_1's l2: 265.244\n",
      "[200]\ttraining's l2: 60.7507\tvalid_1's l2: 235.379\n",
      "[300]\ttraining's l2: 38.3622\tvalid_1's l2: 227.439\n",
      "[400]\ttraining's l2: 24.7185\tvalid_1's l2: 222.197\n",
      "[500]\ttraining's l2: 16.6703\tvalid_1's l2: 220.053\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's l2: 16.6703\tvalid_1's l2: 220.053\n",
      "mse: 220.05330339449375\n"
     ]
    }
   ],
   "source": [
    "## 原生接口\n",
    "\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'regression',\n",
    "    'num_leaves': 31,\n",
    "    'subsample': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction ': 0.8,\n",
    "    'slient': 1,\n",
    "    'learning_rate ': 0.01,\n",
    "    'seed': 0\n",
    "}\n",
    "\n",
    "\n",
    "# 构造训练集\n",
    "dtrain = lgb.Dataset(X_train,y_train)\n",
    "dtest = lgb.Dataset(X_test,y_test)\n",
    "num_rounds = 500\n",
    "\n",
    "# 训练\n",
    "model = lgb.train(params,dtrain, num_rounds, valid_sets=[dtrain, dtest], \n",
    "                  verbose_eval=100, early_stopping_rounds=100)\n",
    "\n",
    "# 预测\n",
    "y_pred = model.predict(X_test,num_iteration=model.best_iteration)\n",
    "print('mse:', mean_squared_error(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d86c190dfcadcdaa67edec4a1ea82702241987b5b1f320c920d3d4ca36fee5b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
