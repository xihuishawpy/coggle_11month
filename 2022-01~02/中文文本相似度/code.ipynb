{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务1：报名比赛，下载比赛数据集并完成读取\n",
    "\n",
    "- 步骤1 ：登录&报名比赛：https://aistudio.baidu.com/aistudio/competition/detail/45/0/task-definition\n",
    "- 步骤2 ：下载比赛数据集\n",
    "- 步骤3 ：使用Pandas完成数据读取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import jieba\n",
    "import distance \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False #用来正常显示负号\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve, accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, KBinsDiscretizer, LabelEncoder, MinMaxScaler, PowerTransformer\n",
    "\n",
    "pal = sns.color_palette()\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'D:/study_hard/statistic/千言数据集'\n",
    "data_list = ['bq_corpus','lcqmc','paws-x-zh']\n",
    "# data_dir = 'E:/学习/千言数据集/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先读一个数据集，后面统一读\n",
    "\n",
    "train = pd.read_csv(data_dir+'/bq_corpus/train.tsv',sep='\\t',error_bad_lines=False,names=['q1','q2','label']).dropna()\n",
    "test = pd.read_csv(data_dir+'/bq_corpus/test.tsv',sep='\\t',error_bad_lines=False,names=['q1','q2']).dropna()\n",
    "test['label'] = -1 \n",
    "dev = pd.read_csv(data_dir+'/bq_corpus/dev.tsv',sep='\\t',error_bad_lines=False,names=['q1','q2','label']).dropna()\n",
    "\n",
    "# label非[0,1]的不处理\n",
    "if len(set(train.label))>2:\n",
    "    train = train[train['label'].isin(['0', '1'])]\n",
    "    train['label'] = train['label'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务2：对句子对提取TFIDF以及统计特征，训练和预测\n",
    "\n",
    "参考代码：https://www.kaggle.com/anokas/data-analysis-xgboost-starter-0-35460-lb\n",
    "- 步骤1 ：对句子对（句子A和句子B统计）如下特征：\n",
    "    - 句子A包含的字符个数、句子B包含的字符个数\n",
    "    - 句子A与句子B的编辑距离\n",
    "    - 句子A与句子B共有单词的个数\n",
    "    - 句子A与句子B共有字符的个数\n",
    "    - 句子A与句子B共有单词的个数 / 句子A字符个数\n",
    "    - 句子A与句子B共有单词的个数 / 句子B字符个数\n",
    "- 步骤2 ：计算TFIDF，并对句子A和句子B进行特征转换，并进行\n",
    "- 步骤3 ：计算句子A与句子B的TFIDF向量的内积距离\n",
    "- 步骤4 ：将上述特征送入分类模型，训练并预测，将结果预测提交到比赛网站。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\CEALLA~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model from cache C:\\Users\\CEALLA~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.535 seconds.\n",
      "Loading model cost 0.535 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# 句子对特征\n",
    "\n",
    "# 字符个数\n",
    "train['q1_len'] = train['q1'].apply(len)\n",
    "train['q2_len'] = train['q2'].apply(len)  \n",
    "\n",
    "# 编辑距离 \n",
    "# Levenshtein Distance 被称为编辑距离（Edit Distance），一个度量两个字符序列之间差异的字符串度量标准\n",
    "train['Lev_distance'] = train.apply(lambda x:distance.levenshtein(x['q1'],x['q2']),axis=1)\n",
    "\n",
    "## jieba分词 \n",
    "# cut_all=True，全模式，“我来到北京清华大学”-->“ 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学”\n",
    "def jieba_cut(sentence):\n",
    "    word_list = jieba.lcut(sentence,cut_all=True) \n",
    "    return word_list \n",
    "\n",
    "train['q1_cut'] = train['q1'].apply(lambda x:jieba_cut(x)) \n",
    "train['q2_cut'] = train['q2'].apply(lambda x:jieba_cut(x)) \n",
    "\n",
    "# 分词后的词个数\n",
    "train['q1_cut_len'] = train['q1_cut'].apply(len)\n",
    "train['q2_cut_len'] = train['q2_cut'].apply(len)  \n",
    "   \n",
    "# 分词后，两句子相同词占所有词（去重）的比例\n",
    "def percent(q1_cut,q2_cut):\n",
    "    inter_num = len(set(q1_cut) & set(q2_cut))\n",
    "    percent = inter_num/len(set(q1_cut))\n",
    "    return percent\n",
    "\n",
    "train['q1_cut_percent'] = train.apply(lambda x: percent(x['q1_cut'],x['q2_cut']),axis=1)\n",
    "train['q2_cut_percent'] = train.apply(lambda x: percent(x['q2_cut'],x['q1_cut']),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 获取停词 \n",
    "# https://github.com/goto456/stopwords\n",
    "\n",
    "def stopwords():\n",
    "    stop_words =[]\n",
    "    with open('cn_stopwords.txt','r',encoding='UTF-8') as f:\n",
    "        for i in f.readlines():\n",
    "            i = i.replace('\\n','')\n",
    "            stop_words.append(i)\n",
    "    return stop_words\n",
    "\n",
    "# 词共享 比例\n",
    "def word_match_share(row,stops):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    # 剔除停词\n",
    "    for word in str(row['q1_cut']):\n",
    "        if word not in stops:\n",
    "            q1words[word] = 1\n",
    "    for word in str(row['q2_cut']):\n",
    "        if word not in stops:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n",
    "    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n",
    "    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n",
    "    return R\n",
    "\n",
    "\n",
    "\n",
    "train['word_match'] = train.apply(lambda x: word_match_share(x,stopwords()),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf 相似度\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# 准备语料\n",
    "def all_words(train):\n",
    "    corpus = []\n",
    "    # 遍历每行，q1分词，q2分词，合并\n",
    "    for row_id in range(len(train)):\n",
    "        row = train.iloc[row_id]\n",
    "        all_words = list()\n",
    "        all_words.extend([word for word in row['q1_cut'] if word not in stopwords()])\n",
    "        all_words.extend([word for word in row['q2_cut'] if word not in stopwords()])\n",
    "        corpus.append(' '.join(all_words))\n",
    "    return corpus\n",
    "\n",
    "corpus = all_words(train)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words and weights: \n",
      "\n",
      "[('还款', 2.7687792452307778e-05), ('微粒', 2.9992202027472856e-05), ('贷', 3.0422878004259203e-05), ('借款', 3.2968482131082684e-05), ('电话', 3.743075310675251e-05), ('没有', 3.885003885003885e-05), ('银行', 3.979465955668749e-05), ('微', 4.773953310736621e-05), ('额度', 4.9089391782435816e-05), ('你好', 5.270092226613966e-05)]\n",
      "\n",
      "Least common words and weights: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('手机卡', 9.998000399920016e-05),\n",
       " ('门', 9.998000399920016e-05),\n",
       " ('装傻', 9.998000399920016e-05),\n",
       " ('私聊', 9.998000399920016e-05),\n",
       " ('看开', 9.998000399920016e-05),\n",
       " ('网点', 9.998000399920016e-05),\n",
       " ('退钱', 9.998000399920016e-05),\n",
       " ('察看', 9.998000399920016e-05),\n",
       " ('6624', 9.998000399920016e-05),\n",
       " ('算下来', 9.998000399920016e-05)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = (' '.join(corpus).split())\n",
    "word_cnt = Counter(corpus)\n",
    "\n",
    "# 定义权重\n",
    "# 词个数为1的，权重为0，大于1的，权重为 1/(count+10000)\n",
    "def get_weight(cnt, eps=10000, min_count=2):\n",
    "    if cnt < min_count:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 / (cnt + eps)\n",
    "    \n",
    "# 生成词权重，词--权重\n",
    "weight =  { word:get_weight(cnt) for word ,cnt in word_cnt.items()}\n",
    "\n",
    "print('Most common words and weights: \\n')\n",
    "print(sorted(weight.items(), key=lambda x: x[1] if x[1] > 0 else 9999)[:10])\n",
    "print('\\nLeast common words and weights: ')\n",
    "(sorted(weight.items(), key=lambda x: x[1], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_word_match_share(row,weight):\n",
    "    q1words = {word:1 for word in row['q1_cut'] if word not in stopwords()}\n",
    "    q2words = {word:1 for word in row['q2_cut'] if word not in stopwords()}\n",
    "    if len(q1words)==0 or len(q2words)==0:\n",
    "        return 0 \n",
    "    \n",
    "    # 获取共享词的权重\n",
    "    shared_weights = [weight.get(w,0) for w in q1words.keys() if w in q2words] + [weight.get(w,0) for w in q2words.keys() if w in q1words]\n",
    "    # 总权重\n",
    "    total_weights = [weight.get(w, 0) for w in q1words] + [weight.get(w, 0) for w in q2words]\n",
    "    # 共享词权重比例\n",
    "    R = np.sum(shared_weights) / np.sum(total_weights)\n",
    "    return R\n",
    "\n",
    "train['tfidf_word_match'] = train.apply(lambda x:tfidf_word_match_share(x,weight),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['q1_len'] = test['q1'].apply(len)\n",
    "test['q2_len'] = test['q2'].apply(len)  \n",
    "\n",
    "# 编辑距离 \n",
    "# Levenshtein Distance 被称为编辑距离（Edit Distance），一个度量两个字符序列之间差异的字符串度量标准\n",
    "test['Lev_distance'] = test.apply(lambda x:distance.levenshtein(x['q1'],x['q2']),axis=1)\n",
    "\n",
    "# 分词\n",
    "test['q1_cut'] = test['q1'].apply(lambda x:jieba_cut(x)) \n",
    "test['q2_cut'] = test['q2'].apply(lambda x:jieba_cut(x)) \n",
    "\n",
    "# 分词后的词个数\n",
    "test['q1_cut_len'] = test['q1_cut'].apply(len)\n",
    "test['q2_cut_len'] = test['q2_cut'].apply(len)  \n",
    "   \n",
    "test['q1_cut_percent'] = test.apply(lambda x: percent(x['q1_cut'],x['q2_cut']),axis=1)\n",
    "test['q2_cut_percent'] = test.apply(lambda x: percent(x['q2_cut'],x['q1_cut']),axis=1)\n",
    "\n",
    "test['word_match'] = test.apply(lambda x: word_match_share(x,stopwords()),axis=1)\n",
    "\n",
    "# tf-idf 相似度\n",
    "corpus = all_words(test)            \n",
    "corpus = (' '.join(corpus).split())\n",
    "word_cnt = Counter(corpus)\n",
    "\n",
    "# 定义权重\n",
    "# 生成词权重，词--权重\n",
    "weight =  { word:get_weight(cnt) for word ,cnt in word_cnt.items()}\n",
    "test['tfidf_word_match'] = test.apply(lambda x:tfidf_word_match_share(x,weight),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "def train_lgb_kfold(X_train, y_train, X_test, n_fold=5):\n",
    "    '''train lightgbm with k-fold split'''\n",
    "    gbms = []\n",
    "    kfold = StratifiedKFold(n_splits=n_fold, random_state=2021, shuffle=True)\n",
    "    oof_preds = np.zeros((X_train.shape[0],))\n",
    "    test_preds = np.zeros((X_test.shape[0],))\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X_train, y_train)):\n",
    "        X_tr, X_val, y_tr, y_val = X_train.iloc[train_index], X_train.iloc[val_index], y_train[train_index], y_train[val_index]\n",
    "        dtrain = lgb.Dataset(X_tr, y_tr)\n",
    "        dvalid = lgb.Dataset(X_val, y_val, reference=dtrain)\n",
    "\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'num_leaves': 512,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'subsample_freq': 1,\n",
    "            'reg_alpha': 0.5,\n",
    "            'reg_lambda': 0.5,\n",
    "            'n_estimators': 5000,\n",
    "            'learning_rate': 0.005,\n",
    "            'min_data_in_leaf': 150,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.7,\n",
    "            'n_jobs': -1,\n",
    "            'seed': 2021\n",
    "        }\n",
    "\n",
    "        gbm = lgb.train(params,\n",
    "                        dtrain,\n",
    "                        num_boost_round=100,\n",
    "                        valid_sets=[dtrain, dvalid],\n",
    "                        verbose_eval=50,\n",
    "                        early_stopping_rounds=20)\n",
    "\n",
    "        oof_preds[val_index] = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "        test_preds += gbm.predict(X_test, num_iteration=gbm.best_iteration) / kfold.n_splits\n",
    "        gbms.append(gbm)\n",
    "\n",
    "    return gbms, oof_preds, test_preds\n",
    "\n",
    "\n",
    "def train_lgb(train, test, feat_cols, label_col, n_fold=5):\n",
    "    '''训练lightgbm'''\n",
    "    X_train = train[feat_cols]\n",
    "    y_train = train[label_col]\n",
    "    X_test = test[feat_cols]\n",
    "    gbms_lgb, oof_preds_lgb, test_preds_lgb = train_lgb_kfold(X_train, y_train, X_test, n_fold=n_fold)\n",
    "    \n",
    "    return gbms_lgb, oof_preds_lgb, test_preds_lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=86194, step=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\installed\\Development\\my_anaconda\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 34518, number of negative: 34437\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 501\n",
      "[LightGBM] [Info] Number of data points in the train set: 68955, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500587 -> initscore=0.002349\n",
      "[LightGBM] [Info] Start training from score 0.002349\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\ttraining's auc: 0.722226\tvalid_1's auc: 0.70973\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.722114\tvalid_1's auc: 0.709784\n",
      "[LightGBM] [Info] Number of positive: 34518, number of negative: 34437\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 504\n",
      "[LightGBM] [Info] Number of data points in the train set: 68955, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500587 -> initscore=0.002349\n",
      "[LightGBM] [Info] Start training from score 0.002349\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's auc: 0.719506\tvalid_1's auc: 0.720813\n",
      "[LightGBM] [Info] Number of positive: 34517, number of negative: 34438\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 505\n",
      "[LightGBM] [Info] Number of data points in the train set: 68955, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500573 -> initscore=0.002291\n",
      "[LightGBM] [Info] Start training from score 0.002291\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's auc: 0.722953\tvalid_1's auc: 0.706694\n",
      "[LightGBM] [Info] Number of positive: 34517, number of negative: 34438\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500\n",
      "[LightGBM] [Info] Number of data points in the train set: 68955, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500573 -> initscore=0.002291\n",
      "[LightGBM] [Info] Start training from score 0.002291\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's auc: 0.720635\tvalid_1's auc: 0.713921\n",
      "[LightGBM] [Info] Number of positive: 34518, number of negative: 34438\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 503\n",
      "[LightGBM] [Info] Number of data points in the train set: 68956, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500580 -> initscore=0.002320\n",
      "[LightGBM] [Info] Start training from score 0.002320\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's auc: 0.718759\tvalid_1's auc: 0.722935\n"
     ]
    }
   ],
   "source": [
    "feat_cols = ['Lev_distance','word_match', 'tfidf_word_match']\n",
    "\n",
    "train.index = train.reset_index(drop=True).index\n",
    "\n",
    "gbms_lgb, oof_preds_lgb, test_preds_lgb = train_lgb(train, test,\n",
    "                                                    feat_cols=feat_cols,\n",
    "                                                    label_col='label')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d86c190dfcadcdaa67edec4a1ea82702241987b5b1f320c920d3d4ca36fee5b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
